{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}\n",
    "\n",
    "Let's start by importing all necessary modules and setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'AbXtract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     11\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAbXtract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAbXtract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AntibodyDescriptorCalculator, Config, load_config\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAbXtract\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     SequenceLiabilityAnalyzer,\n\u001b[1;32m     17\u001b[0m     BashourDescriptorCalculator,\n\u001b[1;32m     18\u001b[0m     PeptideDescriptorCalculator,\n\u001b[1;32m     19\u001b[0m     AntibodyNumbering\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'AbXtract'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from AbXtract import *\n",
    "from AbXtract import AntibodyDescriptorCalculator, Config, load_config\n",
    "from AbXtract.sequence import (\n",
    "    SequenceLiabilityAnalyzer,\n",
    "    BashourDescriptorCalculator,\n",
    "    PeptideDescriptorCalculator,\n",
    "    AntibodyNumbering\n",
    ")\n",
    "from AbXtract.structure import (\n",
    "    SASACalculator,\n",
    "    ChargeAnalyzer,\n",
    "    DSSPAnalyzer,\n",
    "    PropkaAnalyzer,\n",
    "    ArpeggioAnalyzer\n",
    ")\n",
    "from AbXtract.utils import (\n",
    "    read_fasta,\n",
    "    write_fasta,\n",
    "    parse_sequence,\n",
    "    validate_sequence\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default configuration\n",
    "custom_config = Config()\n",
    "\n",
    "'''\n",
    "# Test custom configuration\n",
    "custom_config = Config.from_dict({\n",
    "    'pH': 7.4,\n",
    "    'numbering_scheme': 'kabat',\n",
    "    'verbose': True,\n",
    "    'calculate_dssp': tool_status.get('dssp', False),\n",
    "    'calculate_propka': tool_status.get('propka', False),\n",
    "    'calculate_arpeggio': tool_status.get('arpeggio', False)\n",
    "})\n",
    "'''\n",
    "\n",
    "\n",
    "# Check external tool availability\n",
    "tool_status = custom_config.check_external_tools()\n",
    "print(\"üõ†Ô∏è External Tool Status:\")\n",
    "for tool, available in tool_status.items():\n",
    "    status = \"‚úÖ\" if available else \"‚ùå\"\n",
    "    print(f\"  {tool}: {status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbering = AntibodyNumbering(scheme='imgt')\n",
    "peptide_calc = PeptideDescriptorCalculator()\n",
    "calc = AntibodyDescriptorCalculator(config=custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abxtract_path = \"/home/HX46_FR5/repo_perso/AbXtract\"\n",
    "sys.path.insert(0, abxtract_path)\n",
    "\n",
    "# Set up test data paths\n",
    "BASE_DIR = Path.cwd() \n",
    "DATA_DIR = BASE_DIR / \"data\" / \"test\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Define test file paths\n",
    "RESULTS_DIR = DATA_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input sequence and pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test antibody sequences (based on therapeutic antibodies)\n",
    "HEAVY_SEQUENCE = (\n",
    "    \"QVQLVQSGAEVKKPGASVKVSCKASGGTFSSYAISWVRQAPGQGLEWMGGIIPIFGTANYAQKFQGRVTITADESTSTAYMELSSLRSEDTAVYYCARSHYGLDYWGQGTLVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKSCDKTHTCPPCPAPELLGGPSVFLFPPKPKDTLMISRTPEVTCVVVDVSHEDPEVKFNWYVDGVEVHNAKTKPREEQYASTYRVVSVLTVLHQDWLNGKEYKCKVSNKALPAPIEKTISKAKGQPREPQVYTLPPSRDELTKNQVSLTCLVKGFYPSDIAVEWESNGQPENNYKTTPPVLDSDGSFFLYSKLTVDKSRWQQGNVFSCSVMHEALHNHYTQKSLSLSPGK\"\n",
    ")\n",
    "# Light chain: Includes realistic VL domain + human kappa constant region  \n",
    "LIGHT_SEQUENCE = (\n",
    "    \"DIQMTQSPSSLSASVGDRVTITCRASHSISSYLAWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPLTFGGGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\"\n",
    ")\n",
    "PDB_FILE = DATA_DIR / \"test.pdb\"  # User will provide this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence validity for numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_valid, heavy_msg = validate_sequence(HEAVY_SEQUENCE)\n",
    "light_valid, light_msg = validate_sequence(LIGHT_SEQUENCE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_numbered = numbering.number_sequence(HEAVY_SEQUENCE, 'H')  # Use VH portion only\n",
    "light_numbered = numbering.number_sequence(LIGHT_SEQUENCE, 'L')  # Use VH portion only\n",
    "\n",
    "annotated_H, cdrs_H = numbering.get_cdr_sequences(heavy_numbered, 'H')\n",
    "annotated_L, cdrs_L = numbering.get_cdr_sequences(light_numbered, 'L')\n",
    "\n",
    "heavy_profiles = numbering.get_peptide_profiles(HEAVY_SEQUENCE)\n",
    "light_profiles = numbering.get_peptide_profiles(LIGHT_SEQUENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Peptide descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_results = peptide_calc.calculate_all(\n",
    "    heavy_sequence=HEAVY_SEQUENCE,\n",
    "    light_sequence=LIGHT_SEQUENCE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Sequence descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_results, liabilities = calc.calculate_sequence_descriptors(\n",
    "    heavy_sequence=HEAVY_SEQUENCE,\n",
    "    light_sequence=LIGHT_SEQUENCE,\n",
    "    sequence_id=\"TestAb_Sequence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Sequence descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run structure analysis if PDB is available\n",
    "structure_results_seq, structure_results_comp, df_residues = calc.calculate_structure_descriptors(\n",
    "    pdb_file=PDB_FILE,\n",
    "    structure_id=\"TestAb_Structure\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organise outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_valid, light_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heavy_numbered, light_numbered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdrs_H, cdrs_L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotated_H, annotated_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heavy_profiles, light_profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peptide_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "structure_results_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Residue annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating comprehensive heavy chain dataframe\n",
    "def create_comprehensive_df(annotations, hydrophobicity, chain_type='Heavy'):\n",
    "    # Start with basic annotation data\n",
    "    data = []\n",
    "    \n",
    "    for item in annotations:\n",
    "        position_tuple, amino_acid, region = item\n",
    "        position_num = position_tuple[0]\n",
    "        \n",
    "        # Get index for hydrophobicity values (0-based)\n",
    "        idx = position_num - 1\n",
    "        \n",
    "        # Create row with all information\n",
    "        row = {\n",
    "            'position': position_num,\n",
    "            'amino_acid': amino_acid,\n",
    "            'region': region,\n",
    "            'charge_sign': hydrophobicity['charge_sign'][idx] if idx < len(hydrophobicity['charge_sign']) else np.nan,\n",
    "            'hydrophobicity_hw': hydrophobicity['hydrophobicity_hw'][idx] if idx < len(hydrophobicity['hydrophobicity_hw']) else np.nan,\n",
    "            'hydrophobicity_eisenberg': hydrophobicity['hydrophobicity_eisenberg'][idx] if idx < len(hydrophobicity['hydrophobicity_eisenberg']) else np.nan,\n",
    "            'hydrophobicity_rose': hydrophobicity['hydrophobicity_rose'][idx] if idx < len(hydrophobicity['hydrophobicity_rose']) else np.nan,\n",
    "            'hydrophobicity_janin': hydrophobicity['hydrophobicity_janin'][idx] if idx < len(hydrophobicity['hydrophobicity_janin']) else np.nan,\n",
    "            'hydrophobicity_engelman': hydrophobicity['hydrophobicity_engelman'][idx] if idx < len(hydrophobicity['hydrophobicity_engelman']) else np.nan\n",
    "        }\n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_liability_columns(df, chain_type, liabilities_list):\n",
    "    \"\"\"\n",
    "    Add boolean columns for each LIABILITY TYPE (not just the ones present in this chain).\n",
    "    Place these columns BEFORE the position column.\n",
    "    \"\"\"\n",
    "    chain_letter = 'H' if chain_type == 'Heavy' else 'L'\n",
    "    \n",
    "    # Define ALL possible liability types based on your liability definitions\n",
    "    all_liability_types = [\n",
    "        'Unpaired_Cys',\n",
    "        'N-linked_glycosylation',\n",
    "        'Met_oxidation',\n",
    "        'Trp_oxidation',\n",
    "        'Asn_deamidation',\n",
    "        'Asp_isomerisation',\n",
    "        'Lysine_Glycation',\n",
    "        'N-terminal_glutamate',\n",
    "        'Integrin_binding',\n",
    "        'CD11c/CD18_binding',\n",
    "        'Fragmentation',\n",
    "        'Polyreactivity'\n",
    "    ]\n",
    "    \n",
    "    # Initialize ALL liability columns as False\n",
    "    for col_name in all_liability_types:\n",
    "        df[col_name] = False\n",
    "    \n",
    "    # Now mark positions that have each liability based on the actual data\n",
    "    for liability in liabilities_list:\n",
    "        if liability['chain'] == chain_letter:\n",
    "            # Get position range\n",
    "            start_pos = liability['start_position'][0]\n",
    "            end_pos = liability['end_position'][0]\n",
    "            \n",
    "            # Create column name by simplifying the liability name\n",
    "            col_name = liability['name'].split('(')[0].strip().replace(' ', '_').replace('/', '')\n",
    "            \n",
    "            # Mark all positions in range as True\n",
    "            mask = (df['position'] >= start_pos) & (df['position'] <= end_pos)\n",
    "            if mask.any():\n",
    "                df.loc[mask, col_name] = True\n",
    "                print(f\"Marked {mask.sum()} positions for {col_name} in {chain_type} chain (positions {start_pos}-{end_pos})\")\n",
    "    \n",
    "    # Reorder columns: liability columns FIRST, then position, amino_acid, region, then hydrophobicity\n",
    "    liability_cols = all_liability_types\n",
    "    base_cols = ['position', 'amino_acid', 'region']\n",
    "    hydro_cols = ['charge_sign', 'hydrophobicity_hw', 'hydrophobicity_eisenberg', \n",
    "                  'hydrophobicity_rose', 'hydrophobicity_janin', 'hydrophobicity_engelman']\n",
    "    \n",
    "    # New column order: liabilities first, then base, then hydrophobicity\n",
    "    new_order = base_cols + hydro_cols + liability_cols\n",
    "    df = df[new_order]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Extract the liabilities list from the DataFrame\n",
    "# Assuming 'liabilities' is a DataFrame with a column called 'liabilities' containing the list\n",
    "liabilities_list = liabilities['liabilities'].iloc[0]  # Get the list from the first row\n",
    "\n",
    "\n",
    "# Create comprehensive dataframes for both chains\n",
    "df_heavy = create_comprehensive_df(annotated_H, heavy_profiles, 'Heavy')\n",
    "df_light = create_comprehensive_df(annotated_L, light_profiles, 'Light')\n",
    "\n",
    "# Add liability columns to both dataframes\n",
    "df_heavy = add_liability_columns(df_heavy, 'Heavy', liabilities_list)\n",
    "df_light = add_liability_columns(df_light, 'Light', liabilities_list)\n",
    "\n",
    "df_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liabilities_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "    # Antibody sequence liability definitions\n",
    "# Format: liability_name, regions, regex_pattern\n",
    "Unpaired Cys (C),fv,C\n",
    "N-linked glycosylation (NXS/T X not P),fv,N[^P][ST]\n",
    "Met oxidation (M),cdrs;verniers,M\n",
    "Trp oxidation (W),cdrs;verniers,W\n",
    "Asn deamidation (NG NS NT),cdrs;verniers,N[GST]\n",
    "Asp isomerisation (DG DS DT DD DH),cdrs;verniers,D[GSTDH]\n",
    "Lysine Glycation (KE KD EK ED),cdrs;verniers,KE|KD|EK|ED\n",
    "N-terminal glutamate (VH and VL) (E),nterminus,E\n",
    "Integrin binding (RGD RYD LDV),fv,RGD|RYD|LDV\n",
    "CD11c/CD18 binding (GPR),fv,GPR\n",
    "Fragmentation (DP),cdrs;verniers,DP\n",
    "Polyreactivity (RR VG VV VVV WW WWW WXW),fv,RR|VG|VV|VVV|WW|WWW|WXW\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liabilities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liabilities[\"liabilities\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "structure_results_seq.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chain annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peptide_results\n",
    "heavy_valid, light_valid\n",
    "cdrs_H, cdrs_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Antibody annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_results\n",
    "peptide_results\n",
    "heavy_valid, light_valid\n",
    "cdrs_H, cdrs_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "abxtract",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python (abxtract)",
   "language": "python",
   "name": "abxtract"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
